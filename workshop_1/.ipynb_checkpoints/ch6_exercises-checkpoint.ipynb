{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, absolute_import, unicode_literals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Exercises: Week 1, Chapter 6\n",
    "\n",
    "From https://github.com/LSSTC-DSFP/LSSTC-DSFP-Sessions/tree/master/Session2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data:\n",
    "- http://www.astro.caltech.edu/~mjg/SDSS_gals.csv\n",
    "- http://www.astro.caltech.edu/~mjg/SDSS_colors.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Density Estimation\n",
    "\n",
    "For more info see:\n",
    "- https://github.com/LSSTC-DSFP/LSSTC-DSFP-Sessions/blob/13045a2123c8d845846fba5ca88673ab887a6509/Session1/Day3/IntroToVisualization.ipynb\n",
    "- https://github.com/LSSTC-DSFP/LSSTC-DSFP-Sessions/blob/f954d8669c3cfad8676669f4c5640db143b8e606/Session2/Day1/Unsupervised%20machine%20learning.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Plot the redshift distribution of SDSS galaxies. Try out different binning rules like 'scotts', 'freedman', 'knuth', 'blocks'. Then fit the data with a kde and compare to histograms. (Note: You will have to reshape the redshift data and the kde returns log(density).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from astroML.plotting import hist\n",
    "\n",
    "df = pd.read_csv(\"SDSS_gals.csv\")\n",
    "z = df['z']\n",
    "\n",
    "hist(z # complete \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "z_kde = z.reshape(-1, 1)\n",
    "\n",
    "kde = KernelDensity(bandwidth= # complete\n",
    "kde.fit( # complete\n",
    "score = kde.score_samples( # complete\n",
    "        \n",
    "plt.figure()\n",
    "plt.scatter( # complete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Use sklearn's GridSearchCV to optimize the bandwidth parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# use grid search cross-validation to optimize the bandwidth\n",
    "params = {'bandwidth': # complete\n",
    "grid = GridSearchCV( # complete\n",
    "# complete\n",
    "    \n",
    "# Extract the scores and plot them\n",
    "# complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = # complete\n",
    "\n",
    "# use grid search cross-validation to optimize the bandwidth\n",
    "params = {'bandwidth': # complete\n",
    "grid = GridSearchCV( # complete\n",
    "# complete\n",
    "\n",
    "x = np.arange(.0, 40, 1)\n",
    "y = np.arange(-24, -15, 0.2)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "XY = np.array([X.flatten(), Y.flatten()]).transpose()\n",
    "pdf = # complete\n",
    "             \n",
    "# Use imshow to make a color density plot\n",
    "plt.imshow(# complete, interpolation='none', cmap=pl.cm.jet, origin='lower',clip_on=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-neighbors\n",
    "\n",
    "For more info see:\n",
    "- https://github.com/LSSTC-DSFP/LSSTC-DSFP-Sessions/blob/b680396be06ca9085a20e7a3ba12325119b4d6f6/Session2/Day1/ReIntroToMachineLearning.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Classify the seaborn iris dataset with k-neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "sns.pairplot(iris, vars = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"],\n",
    "             hue = \"species\", diag_kind = 'kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You can also load the data as a scikit-learn Bunch which enables dictionary-like properties, and easy integration with all the scikit-learn algorithms.\n",
    "\n",
    "The scikit-learn Bunch consists of several keys, of which we are primarily interested in the data and target information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter( # complete\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('sepal width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Fit two different $k$NN models to the iris data, one with 3 neighbors and one with 10 neighbors. Plot the resulting class predictions in the sepal length-sepal width plane (same plot as above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNNclf = KNeighborsClassifier( # complete \n",
    "preds = # complete \n",
    "plt.figure()\n",
    "plt.scatter( # complete \n",
    "\n",
    "KNNclf = KNeighborsClassifier( # complete \n",
    "preds = # complete \n",
    "plt.figure()\n",
    "plt.scatter( # complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Use cross-validation to obtain accuracies for your kNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "CVpreds = cross_val_predict(# complete\n",
    "plt.figure()\n",
    "plt.scatter( # complete\n",
    "print(\"The accuracy of the kNN = 5 model is ~{:.4}\".format( # complete\n",
    "\n",
    "CVpreds50 = cross_val_predict( # complete\n",
    "\n",
    "print(\"The accuracy of the kNN = 50 model is ~{:.4}\".format( # complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra:** Try calculating the confusion matrix or ROC curve using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means\n",
    "\n",
    "For more info see:\n",
    "- https://github.com/LSSTC-DSFP/LSSTC-DSFP-Sessions/blob/f954d8669c3cfad8676669f4c5640db143b8e606/Session2/Day1/Unsupervised%20machine%20learning.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"SDSS_colors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot Data\n",
    "\n",
    "# Example:\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.pariplot(df, vars=['u_g', 'g_r', 'r_i', 'i_z'], diag_kind = 'kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Try two different k-means models - one with 2 clusters, one with 3 clusters. (You can also try varying other parameters like n_init and init.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "Kcluster = KMeans( # complete\n",
    "# complete\n",
    "    \n",
    "plt.figure()\n",
    "plt.scatter( # complete\n",
    "plt.xlabel('u - g')\n",
    "plt.ylabel('g - r')\n",
    "        \n",
    "Kcluster = KMeans( # complete\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter( # complete\n",
    "plt.xlabel('u - g')\n",
    "plt.ylabel('g - r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** k-means uses Eucliden sitance as its similarity metric, so the magnitude of individual features can have a strong effect on the final clustering outcome. This means that rescaling the data is generally a good idea. Check the mean, std, min, max of each parameter to see if one feature is particularly dominant.\n",
    "\n",
    "**Problem:** Try rescaling the data with the sklearn class StandardScaler()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit_transform( # complete\n",
    "    \n",
    "Kcluster = KMeans( # complete\n",
    "        \n",
    "plt.figure()\n",
    "plt.scatter(# complete\n",
    "plt.xlabel('u - g')\n",
    "plt.ylabel('g - r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** sklearn has another implementation of k-means, MiniBatchKMeans, which is faster, but less accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** To determine the best value of k, try calculating the silhouette score for k values ranging from 2 to 10. The silhouette score is a comparison between the mean intra- and inter-cluster distances. A lower score is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Select a random subset of the data\n",
    "N_small = 100\n",
    "dfSample = df[ # complete\n",
    "    \n",
    "ss = []\n",
    "nn = [2,3,5,10]\n",
    "    \n",
    "for n in # complete\n",
    "    Kcluster = Kmeans( # complete\n",
    "    \n",
    "    ss.append(metrics.silhouette_score( # complete\n",
    "            \n",
    "plt.figure()\n",
    "plt.scatter(# complete\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Mean silhouette')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Models\n",
    "\n",
    "For more info see:\n",
    "- https://github.com/LSSTC-DSFP/LSSTC-DSFP-Sessions/blob/master/Session2/Day2/DSFP2017-EM.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Fit a gaussian mixture model to the rescaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "clf = GaussianMixture(n_components = # complete\n",
    "clf.fit( # complete\n",
    "preds = clf.predict( # complete\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter( # complete\n",
    "plt.xlabel('u - g')\n",
    "plt.ylabel('g - r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering\n",
    "\n",
    "For more info see:\n",
    "- https://github.com/LSSTC-DSFP/LSSTC-DSFP-Sessions/blob/f954d8669c3cfad8676669f4c5640db143b8e606/Session2/Day1/Unsupervised%20machine%20learning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.clustering import AgglomerativeClustering\n",
    "\n",
    "agg = AgglomerativeClustering( # complete\n",
    "agg.fit_predict( # complete\n",
    "                \n",
    "plt.figure()\n",
    "plt.scatter( # complete\n",
    "plt.scatter( # complete\n",
    "plt.xlabel('u - g')\n",
    "plt.ylabel('g - r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
