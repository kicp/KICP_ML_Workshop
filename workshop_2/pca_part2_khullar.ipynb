{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pyfits\n",
    "import specutils\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "from scipy import stats\n",
    "#print(ea.__version__)\n",
    "#import cPickle\n",
    "import string\n",
    "\n",
    "from astropy.table import Table\n",
    "from __future__ import division\n",
    "\n",
    "from astropy.modeling import models, fitting\n",
    "\n",
    "from astropy.io import ascii\n",
    "\n",
    "def plot_pretty(dpi=175, fontsize=9):\n",
    "    # import pyplot and set some parameters to make plots prettier\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.rc(\"savefig\", dpi=dpi)\n",
    "    plt.rc('text', usetex=False)\n",
    "    plt.rc('font', size=fontsize)\n",
    "    plt.rc('xtick.major', pad=5)\n",
    "    plt.rc('xtick.minor', pad=5)\n",
    "    plt.rc('ytick.major', pad=5)\n",
    "    plt.rc('ytick.minor', pad=5)\n",
    "    return\n",
    "\n",
    "plot_pretty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: Dealing with Data\n",
    "\n",
    "For more theory -- visit Part B (second half of this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zoheyr/anaconda/lib/python2.7/site-packages/astroquery/sdss/__init__.py:28: UserWarning: Experimental: SDSS has not yet been refactored to have its API match the rest of astroquery (but it's nearly there).\n",
      "  warnings.warn(\"Experimental: SDSS has not yet been refactored to have its API \"\n"
     ]
    }
   ],
   "source": [
    "# execute this line:\n",
    "from astroquery.sdss import SDSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "&lt;Table length=10000&gt;\n",
       "<table id=\"table4716330576\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>psfMag_r</th><th>fiberMag_r</th><th>fiber2Mag_r</th><th>petroMag_r</th><th>deVMag_r</th><th>expMag_r</th><th>modelMag_r</th><th>cModelMag_r</th><th>class</th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>str6</th></tr></thead>\n",
       "<tr><td>18.50319</td><td>18.65275</td><td>19.33509</td><td>17.54539</td><td>17.31526</td><td>17.58132</td><td>17.58132</td><td>17.48715</td><td>GALAXY</td></tr>\n",
       "<tr><td>19.02659</td><td>19.32441</td><td>19.80892</td><td>19.05827</td><td>19.03468</td><td>19.03111</td><td>19.03111</td><td>19.03111</td><td>STAR</td></tr>\n",
       "<tr><td>19.8809</td><td>19.77895</td><td>20.46623</td><td>19.3534</td><td>19.1864</td><td>19.35493</td><td>19.35493</td><td>19.24559</td><td>GALAXY</td></tr>\n",
       "<tr><td>22.03563</td><td>22.06141</td><td>22.68416</td><td>21.51795</td><td>21.03554</td><td>21.31751</td><td>21.31751</td><td>21.31751</td><td>GALAXY</td></tr>\n",
       "<tr><td>21.56726</td><td>21.57312</td><td>22.22178</td><td>20.4583</td><td>19.93309</td><td>20.39825</td><td>20.39819</td><td>20.20402</td><td>GALAXY</td></tr>\n",
       "<tr><td>18.66813</td><td>18.75309</td><td>19.36792</td><td>17.83372</td><td>17.69468</td><td>17.89914</td><td>17.6947</td><td>17.75269</td><td>GALAXY</td></tr>\n",
       "<tr><td>20.19068</td><td>20.33947</td><td>20.93226</td><td>19.77666</td><td>19.63458</td><td>19.74873</td><td>19.74872</td><td>19.74873</td><td>GALAXY</td></tr>\n",
       "<tr><td>19.41619</td><td>19.38348</td><td>20.15486</td><td>17.67687</td><td>17.16815</td><td>17.63962</td><td>17.63962</td><td>17.63962</td><td>GALAXY</td></tr>\n",
       "<tr><td>18.88878</td><td>18.91179</td><td>19.57415</td><td>17.3317</td><td>17.02896</td><td>17.43539</td><td>17.02898</td><td>17.06256</td><td>GALAXY</td></tr>\n",
       "<tr><td>17.73892</td><td>17.8784</td><td>18.4601</td><td>16.81384</td><td>16.80538</td><td>17.07542</td><td>16.80538</td><td>16.80538</td><td>GALAXY</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>19.24749</td><td>19.50776</td><td>20.10474</td><td>18.66996</td><td>18.61142</td><td>18.78825</td><td>18.61142</td><td>18.61683</td><td>GALAXY</td></tr>\n",
       "<tr><td>18.85847</td><td>19.0704</td><td>19.73915</td><td>17.85506</td><td>17.58484</td><td>17.82618</td><td>17.82618</td><td>17.73945</td><td>GALAXY</td></tr>\n",
       "<tr><td>17.88114</td><td>18.16021</td><td>18.73313</td><td>17.69177</td><td>17.64868</td><td>17.64409</td><td>17.64409</td><td>17.64409</td><td>STAR</td></tr>\n",
       "<tr><td>18.36227</td><td>18.63728</td><td>19.22842</td><td>17.76154</td><td>17.72115</td><td>17.91659</td><td>17.72115</td><td>17.72115</td><td>GALAXY</td></tr>\n",
       "<tr><td>19.39928</td><td>19.56483</td><td>20.29491</td><td>17.66843</td><td>17.08915</td><td>17.55575</td><td>17.55575</td><td>17.55575</td><td>GALAXY</td></tr>\n",
       "<tr><td>18.05847</td><td>18.21004</td><td>18.89647</td><td>16.85453</td><td>16.62304</td><td>16.84302</td><td>16.84302</td><td>16.76329</td><td>GALAXY</td></tr>\n",
       "<tr><td>22.23627</td><td>22.52658</td><td>23.06609</td><td>21.30207</td><td>21.25972</td><td>21.42846</td><td>21.25974</td><td>21.26578</td><td>GALAXY</td></tr>\n",
       "<tr><td>19.66558</td><td>19.97335</td><td>20.53659</td><td>19.27357</td><td>19.22064</td><td>19.36352</td><td>19.22064</td><td>19.22064</td><td>GALAXY</td></tr>\n",
       "<tr><td>20.70572</td><td>21.10135</td><td>21.57685</td><td>20.69317</td><td>20.65731</td><td>20.66223</td><td>20.65733</td><td>20.65731</td><td>STAR</td></tr>\n",
       "<tr><td>21.83704</td><td>22.13966</td><td>22.7099</td><td>21.37834</td><td>21.28071</td><td>21.44025</td><td>21.44045</td><td>21.40327</td><td>GALAXY</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=10000>\n",
       "psfMag_r fiberMag_r fiber2Mag_r petroMag_r ... modelMag_r cModelMag_r class \n",
       "float64   float64     float64    float64   ...  float64     float64    str6 \n",
       "-------- ---------- ----------- ---------- ... ---------- ----------- ------\n",
       "18.50319   18.65275    19.33509   17.54539 ...   17.58132    17.48715 GALAXY\n",
       "19.02659   19.32441    19.80892   19.05827 ...   19.03111    19.03111   STAR\n",
       " 19.8809   19.77895    20.46623    19.3534 ...   19.35493    19.24559 GALAXY\n",
       "22.03563   22.06141    22.68416   21.51795 ...   21.31751    21.31751 GALAXY\n",
       "21.56726   21.57312    22.22178    20.4583 ...   20.39819    20.20402 GALAXY\n",
       "18.66813   18.75309    19.36792   17.83372 ...    17.6947    17.75269 GALAXY\n",
       "20.19068   20.33947    20.93226   19.77666 ...   19.74872    19.74873 GALAXY\n",
       "19.41619   19.38348    20.15486   17.67687 ...   17.63962    17.63962 GALAXY\n",
       "18.88878   18.91179    19.57415    17.3317 ...   17.02898    17.06256 GALAXY\n",
       "17.73892    17.8784     18.4601   16.81384 ...   16.80538    16.80538 GALAXY\n",
       "     ...        ...         ...        ... ...        ...         ...    ...\n",
       "19.24749   19.50776    20.10474   18.66996 ...   18.61142    18.61683 GALAXY\n",
       "18.85847    19.0704    19.73915   17.85506 ...   17.82618    17.73945 GALAXY\n",
       "17.88114   18.16021    18.73313   17.69177 ...   17.64409    17.64409   STAR\n",
       "18.36227   18.63728    19.22842   17.76154 ...   17.72115    17.72115 GALAXY\n",
       "19.39928   19.56483    20.29491   17.66843 ...   17.55575    17.55575 GALAXY\n",
       "18.05847   18.21004    18.89647   16.85453 ...   16.84302    16.76329 GALAXY\n",
       "22.23627   22.52658    23.06609   21.30207 ...   21.25974    21.26578 GALAXY\n",
       "19.66558   19.97335    20.53659   19.27357 ...   19.22064    19.22064 GALAXY\n",
       "20.70572   21.10135    21.57685   20.69317 ...   20.65733    20.65731   STAR\n",
       "21.83704   22.13966     22.7099   21.37834 ...   21.44045    21.40327 GALAXY"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TSquery = \"\"\"SELECT TOP 10000 \n",
    "             p.psfMag_r, p.fiberMag_r, p.fiber2Mag_r, p.petroMag_r, \n",
    "             p.deVMag_r, p.expMag_r, p.modelMag_r, p.cModelMag_r, \n",
    "             s.class\n",
    "             FROM PhotoObjAll AS p JOIN specObjAll s ON s.bestobjid = p.objid\n",
    "             WHERE p.mode = 1 AND s.sciencePrimary = 1 AND p.clean = 1 AND s.class != 'QSO'\n",
    "             ORDER BY p.objid ASC\n",
    "               \"\"\"\n",
    "SDSSts = SDSS.query_sql(TSquery)\n",
    "SDSSts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Visualize this data set. What representation is most appropriate, do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating a dataset in the right format?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# set the random state\n",
    "rs = 23  # we are in Chicago after all\n",
    "\n",
    "# extract feature names, remove class\n",
    "feats = list(SDSSts.columns)\n",
    "feats.remove('class')\n",
    "\n",
    "# cast astropy table to pandas, remove classes\n",
    "X = np.array(SDSSts[feats].to_pandas())\n",
    "\n",
    "# our classes are the outcomes to classify on\n",
    "y = np.array(SDSSts['class'])\n",
    "\n",
    "# let's do a split in training and test set:\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validating Multiple Model Components\n",
    "\n",
    "In most machine learning applications, your machine learning algorithm might not be the only component having free parameters. You might not even be sure which machine learning algorithm to use! \n",
    "\n",
    "For demonstration purposes, imagine you have many features, but many of them might be correlated. A standard dimensionality reduction technique to use is [Principal Component Analysis](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). \n",
    "\n",
    "**Exercise 4**: The number of features in our present data set is pretty small, but let's nevertheless attempt to reduce dimensionality with PCA. Run a PCA decomposition in 2 dimensions and plot the results. Colour-code stars versus calaxies. How well do they separate along the principal components?\n",
    "\n",
    "*Hint*: Think about whether you can run PCA on training and test set separately, or whether you need to run it on both together *before* doing the train-test split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# instantiate the PCA object\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# fit and transform the samples:\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# make a plot object\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12,8))\n",
    "\n",
    "# loop over number of classes:\n",
    "for i,l in enumerate(np.unique(y)):\n",
    "    members = y == l\n",
    "    plt.scatter(X_pca[members, 0], X_pca[members, 1], \n",
    "                color=sns.color_palette(\"colorblind\",8)[i],\n",
    "                label=l)\n",
    "    \n",
    "ax.set_xlabel(\"PCA Component 1\")\n",
    "ax.set_ylabel(\"PCA Component 2\")\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how do we know whether two components was really the right number to choose? perhaps it should have been three? Or four? Ideally, we would like to include the feature engineering in our cross validation procedure. In principle, you can do this by running a complicated for-loop. In practice, this is what `scikit-learn`s [Pipeline](http://scikit-learn.org/stable/modules/pipeline.html) is for! A `Pipeline` object takes a list of tuples of `(\"string\", ScikitLearnObject)` pairs as input and strings them together (your feature vector `X` will be put first through the first object, then the second object and so on sequentially).\n",
    "\n",
    "**Note**: `scikit-learn` distinguishes between *transformers* (i.e. classes that transform the features into something else, like PCA, t-SNE, StandardScaler, ...) and *predictors* (i.e. classes that produce predictions, such as random forests, logistic regression, ...). In a pipeline, all but the last objects must be transformers; the last object can be either.\n",
    "\n",
    "**Exercise 6**: Make a pipeline including (1) a PCA object and (2) a random forest classifier. Cross-validate both the PCA components and the parameters of the random forest classifier. What is the best number of PCA components to use?\n",
    "\n",
    "*Hint*: You can also use the convenience function [`make_pipeline`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline) to creatue your pipeline. \n",
    "\n",
    "*Hint*: Check the documentation for the precise notation to use for cross-validating parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# make a list of name-estimator tuples\n",
    "estimators = [('pca', PCA()), ('clf', RandomForestClassifier())]\n",
    "\n",
    "# instantiate the pipeline\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "# make a dictionary of parameters\n",
    "params = dict(pca__n_components=[2, 4, 6, 8],\n",
    "              clf__n_estimators=[10, 100, 300],\n",
    "              clf__min_samples_leaf=[1,10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: A different approach, a different dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A consistent problem for visualizing large datasets is that almost all projections of the data must be rendered in two dimensions so they can be displayed on the page or screen. While it is possible to capture a greater deal of dimensionality (3D projection, point color, point size, point symbol, etc.) by getting a little creative, these methods are highly inadequate for data sets in 10s, 100s, or millions (Google) of dimensions.\n",
    "\n",
    "A solution for this problem is dimesionality reduction. The goal is to identify a new set of artificial features that reduces the overall size of the data set while still capturing most of the variance of the original data (some instances require a similar, but different, goal of identifying which features contain the least information and removing those from the model).\n",
    "\n",
    "#### Digits Data Set\n",
    "\n",
    "There are many different algorithms that can be used to perform dimensionality reduction. Today we will introduce a few, and develop some intuition by example. To illustrate these examples, we will use the famous digits data set, which includes images of hand-written digits from 0-9. The images are segmented into an 8 x 8 [64] grid, with the intensity recorded in each pixel recorded on a scale from 0-16. *Note* - our data structure will deal with \"flattened\", length = 64, 1D arrays for each of the 1797 digits in the training set.\n",
    "\n",
    "Historical aside - the use of machine learning to classify this famous data set has saved the USPS billions of dollars as computers can now scan and automatically direct > 98% of all mail based on the written zipcodes.\n",
    "\n",
    "At face value, we do not have a good means for visualizing this 64 dimension data set, but dimensionality reduction can help us understand the structure of the data. Let us begin by loading and examining the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(np.shape(digits.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As has already been noted - there are 64 pixels used to describe 1797 different characters. We can reshape the data to see how the digits actually appear:\n",
    "Note - this example shows the first digit in the data set, feel free to examine others. If you cannot tell what digit you are looking at, you can access that via digits.target[digit_num]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digit_num = 0\n",
    "\n",
    "print(digits.data[digit_num])  # show the flattened array\n",
    "grid_data = np.reshape(digits.data[digit_num], (8,8))  # reshape from 1d to 2d pixel array\n",
    "plt.imshow(grid_data, interpolation = \"nearest\", cmap = \"bone_r\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Component Analysis\n",
    "\n",
    "Probably the most famous (not to be confused with the best) method of dimensionality reduction adopted throughout the astronomical literature is [Principal Component Analysis](https://en.wikipedia.org/wiki/Principal_component_analysis) (PCA). We will skip the detailed mathematics, but in short, PCA aims to reduce the dimensionality by transforming the data set to a set of linearly uncorrelated variables called principle components. The transformation is accomplished following a singular value decomposition (SVD) of the data matrix, $X$, and in many instances most of the variance of the data is retained with only a few principle components. Advantages of PCA include that it is deterministic, and in many cases, fast. One of the main disadvantages is that PCA imposes linearity and orthogonality on the projected components, which may not be adequate to describe the underlying manifold of the data (as an aside - PCA was developed over a century ago, statisticians have crafted many alternatives in the intervening time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have determined that the two most important pixels for differentiating digits as (0-indexed) pixels 52 and 36.  (Note - we will discuss further how I determined this tomorrow.) \n",
    "\n",
    "**Problem 2a** Establish a baseline for the performance of our various dimensionality reduction techniques by plotting (0-indexed) pixel 52 against pixel 36 for the digits data set. Color the points by the digit they represent. \n",
    "\n",
    "*Hint - this is one application where the choice of color map **really** matters. I recommend `nipy_spectral`, and this is the rare case where `jet` is a good choice.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter( digits.data[:, 52], \n",
    "             digits.data[:, 36], \n",
    "             c = digits.target, cmap = \"nipy_spectral\", edgecolor = \"None\")\n",
    "plt.xlabel('pixel 52')\n",
    "plt.ylabel('pixel 36')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot we see that just these two pixels do a decent job of clustering the data: the zeros are in the lower-right corner and the 7s are in the upper-right. However, there is a lot of confusion among the other digits, meaning these two pixels only capture a small fraction of the variance in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an attempt to capture even more of the variance, we will now project the data using PCA. Again, brushing over the mathematical details, the PCA model projects the data with the following form:\n",
    "\n",
    "$$x_i = \\mu + \\sum_{j = 1}^n a_{ij} v_j$$\n",
    "\n",
    "where $x_i$ represents an individual digit image, $\\mu$ represents the mean digit image, while the sum is over the eigenvectors (principal components) of the model $v_j$. The standard procedure is to list the most important eigenvectors with low $j$. In many cases, it is possible to capture most of the variance in the data using only the first few eigenvectors. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will project the data using the [`PCA`](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA) function within the [`sklearn.decomposition`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition) module. PCA models are fit in the following fashion:\n",
    "\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components = None)\n",
    "    pca.fit(X)\n",
    "    \n",
    "where `n_components` is the number of PCA components to retain (the default is the minimum between the number of samples and number of features), and `X` is the feature array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2b** Fit for the digits data set for the 2 leading PCA components. \n",
    "\n",
    "*Note - this isn't essential for this problem, but SVD on large matricies is computationally expensive $\\mathcal{O}[N^3]$. For very large data sets [`RandomizedPCA`](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.RandomizedPCA.html) can significantly improve computation times, at the cost of some accuracy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "pca = PCA(n_components = 2)\n",
    "pca.fit(digits.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fit the PCA model, we can transform the data using the `.transform()` method, which requires a feature array as input. \n",
    "\n",
    "**Problem 2c** Transform the digits data to the 2 leading PCA components, and make a scatter plot of the data in this projection. Color the points by their respective digits. How does this separation of the data compare to the use of just pixels 52 and 36?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_j = pca.transform(digits.data)\n",
    "\n",
    "plt.scatter(v_j[:,0], v_j[:,1], c = digits.target, cmap = \"nipy_spectral\", edgecolor = \"None\")\n",
    "plt.xlabel(r'$a_{i1}$', fontsize = 20)\n",
    "plt.ylabel(r'$a_{i2}$', fontsize = 20)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that the PCA projection clusters (and visualizes) the data in a much more meaningful way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual SVD eignvectors can be accessed via the `.components_` attribute, while the variance explained by each component is stored in the `.explained_variance_ratio_`.\n",
    "\n",
    "**Problem 2d** Determine the variance explained by each of the components, as well as the total variance explained by the two components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The first component explains {:.3f} of the variance in the data.\".format(pca.explained_variance_ratio_[0]))\n",
    "print(\"The second component explains {:.3f} of the variance in the data.\".format(pca.explained_variance_ratio_[1]))\n",
    "print(\"The top 2 components explain {:.3f} of the variance in the data.\".format(sum(pca.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2e** How many components are needed to explain 90% of the variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for num_feats in np.arange(1,65, dtype = int):\n",
    "    pca = PCA(n_components = num_feats)\n",
    "    pca.fit(digits.data)\n",
    "    variance_explained = sum(pca.explained_variance_ratio_)\n",
    "    if variance_explained >= .90:\n",
    "        break\n",
    "print(\"{:d} features are needed to explain 90% of the variance\".format(num_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started with 64 features to describe the digits dataset, and now we are able to project those features into a 21-D space that captures 90% of the original variance. Doing so has allowed us to readily separate the different characters via a 2-D projection, which makes it easy to see the difference between the different numbers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction is useful beyond the visualization of high-dimensional data sets. It is often used as a preprocessing step before passing data to machine-learning models (imagine Google with $10^6$ features - if this can be reduced to $\\sim{10}\\mathrm{s}$ it will greatly improve the run time of the algorithms. PCA in particular removes correlation between the features, which is particularly useful for some algorithms, like Support Vector Machines. Finally, for a method like PCA, the eigenvectors can provide insight into the meaning of the principal components. Once again, our very own Jake VanderPlas has put together a nice tutorial on [extracting and visualing the eigenvectors of SDSS galaxy spectra](http://www.astroml.org/sklearn_tutorial/dimensionality_reduction.html). A brief note of caution - astronomers will often try to derive physical insight from PCA eigenspectra or eigentimeseries, but this is not advisable as there is no physical reason for the data to be linearly and orthogonally separable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Manifold Learning\n",
    "\n",
    "*Why the advised caution against PCA?* As already noted, newer, more flexible methods have been developed. Furthermore, it is possible that the data of interest have interesting non-linear structure, which is not easily identified via PCA-like projections. Thus, an entire field, known as [Manifold Learning](http://scikit-learn.org/stable/modules/manifold.html), has been developed, with several algorithms available via the [`sklearn.manifold`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.manifold) module. \n",
    "\n",
    "Aside: I will note that an advantage of PCA is its deterministic nature, leading to stable repeatability. The results from most non-linear manifold-learning methods change from run to run.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
